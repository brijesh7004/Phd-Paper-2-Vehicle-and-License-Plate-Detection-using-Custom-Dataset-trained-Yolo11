{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G4J96-nIHcJX","executionInfo":{"status":"ok","timestamp":1765378112905,"user_tz":-330,"elapsed":22718,"user":{"displayName":"MATLAB PROJECT","userId":"00610724416781930528"}},"outputId":"5a7ca1cd-c865-4882-ca1f-b18c9dc0e12a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install ultralytics #==8.2.103 -q\n","!yolo settings sync=False\n","\n","import ultralytics\n","ultralytics.checks()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"na9-ycFVHu1u","executionInfo":{"status":"ok","timestamp":1765378128280,"user_tz":-330,"elapsed":15379,"user":{"displayName":"MATLAB PROJECT","userId":"00610724416781930528"}},"outputId":"49fd3bf3-5dc5-4013-eac1-7602791ceb10"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.235 ðŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","Setup complete âœ… (2 CPUs, 12.7 GB RAM, 38.3/112.6 GB disk)\n"]}]},{"cell_type":"code","source":["import os\n","import glob\n","import time\n","import csv\n","from pathlib import Path\n","\n","import cv2\n","import matplotlib.pyplot as plt\n","from ultralytics import YOLO\n","\n","\n","GDrive_DIR = \"/content/drive/MyDrive/Phd Projects/DPC-4 Works\"\n","os.chdir(GDrive_DIR)\n","\n","# Models\n","MODEL_DIR = \"models\"\n","MODEL_PATHS = {\n","    \"yolov8l_base\": os.path.join(MODEL_DIR, \"yolov8l.pt\"),\n","    \"yolo11l_base\": os.path.join(MODEL_DIR, \"yolo11l.pt\"),\n","    \"yolo11l_trained\": os.path.join(MODEL_DIR, \"yolo11l_251019.pt\"),\n","}\n","\n","# Image & video inputs\n","IMAGES_DIR = \"data/images\"\n","\n","# Dataset for mAP evaluation\n","DATA_YAML = \"data/data.yaml\"\n","VAL_SPLIT = \"val\"                     # \"val\" or \"test\"\n","\n","# Inference settings\n","DEVICE = 0            # 0 for first GPU, or \"cpu\"\n","IMG_SIZE = 640\n","CONF_THRES = 0.7\n","IOU_THRES = 0.45\n","MAX_VIDEO_FRAMES = 300   # limit for timing; set None to use full video\n","\n","# Output root\n","OUTPUT_ROOT = \"outputs_compare\"\n","IMAGE_PRED_DIR = os.path.join(OUTPUT_ROOT, \"images\")\n","VIDEO_PRED_DIR = os.path.join(OUTPUT_ROOT, \"videos\")\n","REPORTS_DIR = os.path.join(OUTPUT_ROOT, \"reports\")\n","PLOTS_DIR = os.path.join(OUTPUT_ROOT, \"plots\")\n","\n","for d in [IMAGE_PRED_DIR, VIDEO_PRED_DIR, REPORTS_DIR, PLOTS_DIR]:\n","    os.makedirs(d, exist_ok=True)"],"metadata":{"id":"iaqSy5PuHlKZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================================\n","# UTILS\n","# ============================================================\n","\n","def ensure_dir(path: str):\n","    Path(path).mkdir(parents=True, exist_ok=True)\n","\n","\n","def load_models(model_paths: dict):\n","    \"\"\"Load YOLO models from given paths.\"\"\"\n","    models = {}\n","    for name, path in model_paths.items():\n","        print(f\"[INFO] Loading model '{name}' from {path} ...\")\n","        if not os.path.isfile(path):\n","            raise FileNotFoundError(f\"Model file not found: {path}\")\n","        models[name] = YOLO(path)\n","    return models\n","\n","\n","def get_image_paths(images_dir: str):\n","    exts = [\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\"]\n","    files = []\n","    for ext in exts:\n","        files.extend(glob.glob(os.path.join(images_dir, ext)))\n","    files = sorted(files)\n","    print(f\"[INFO] Found {len(files)} images in {images_dir}\")\n","    return files"],"metadata":{"id":"sXjRWIadNrQg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================================\n","# 1) IMAGE INFERENCE BENCHMARK\n","# ============================================================\n","\n","def benchmark_on_images(models: dict, images_dir: str):\n","    image_paths = get_image_paths(images_dir)\n","    if not image_paths:\n","        print(\"[WARN] No images found for image benchmark. Skipping.\")\n","        return\n","\n","    per_image_csv = os.path.join(REPORTS_DIR, \"image_per_image_stats.csv\")\n","    summary_csv = os.path.join(REPORTS_DIR, \"image_summary_stats.csv\")\n","\n","    with open(per_image_csv, \"w\", newline=\"\") as f_per, open(summary_csv, \"w\", newline=\"\") as f_sum:\n","        per_writer = csv.writer(f_per)\n","        sum_writer = csv.writer(f_sum)\n","\n","        per_writer.writerow([\n","            \"model\", \"image_name\", \"latency_sec\",\n","            \"num_detections\", \"mean_confidence\"\n","        ])\n","        sum_writer.writerow([\n","            \"model\", \"num_images\",\n","            \"avg_latency_sec\", \"fps\",\n","            \"avg_num_detections\", \"avg_mean_confidence\"\n","        ])\n","\n","        for model_name, model in models.items():\n","            print(f\"\\n[INFO] IMAGE benchmark for model: {model_name}\")\n","            model_out_dir = os.path.join(IMAGE_PRED_DIR, model_name)\n","            ensure_dir(model_out_dir)\n","\n","            latencies = []\n","            num_dets_list = []\n","            mean_conf_list = []\n","\n","            for img_path in image_paths:\n","                img_name = os.path.basename(img_path)\n","\n","                t0 = time.perf_counter()\n","                results = model(\n","                    source=img_path,\n","                    imgsz=IMG_SIZE,\n","                    conf=CONF_THRES,\n","                    iou=IOU_THRES,\n","                    device=DEVICE,\n","                    verbose=False,\n","                    save=False\n","                )\n","                t1 = time.perf_counter()\n","                dt = t1 - t0\n","                latencies.append(dt)\n","\n","                res = results[0]\n","                boxes = res.boxes\n","                num_dets = 0\n","                mean_conf = 0.0\n","\n","                if boxes is not None and len(boxes) > 0:\n","                    num_dets = len(boxes)\n","                    try:\n","                        mean_conf = float(boxes.conf.mean())\n","                    except Exception:\n","                        mean_conf = 0.0\n","\n","                num_dets_list.append(num_dets)\n","                mean_conf_list.append(mean_conf)\n","\n","                # Save prediction image\n","                plotted = res.plot()\n","                out_path = os.path.join(model_out_dir, img_name)\n","                cv2.imwrite(out_path, plotted)\n","\n","                per_writer.writerow([\n","                    model_name, img_name, f\"{dt:.6f}\",\n","                    num_dets, f\"{mean_conf:.4f}\"\n","                ])\n","\n","            if latencies:\n","                avg_latency = sum(latencies) / len(latencies)\n","                fps = 1.0 / avg_latency if avg_latency > 0 else 0.0\n","                avg_dets = sum(num_dets_list) / len(num_dets_list)\n","                avg_conf = sum(mean_conf_list) / len(mean_conf_list)\n","\n","                sum_writer.writerow([\n","                    model_name,\n","                    len(image_paths),\n","                    f\"{avg_latency:.6f}\",\n","                    f\"{fps:.2f}\",\n","                    f\"{avg_dets:.3f}\",\n","                    f\"{avg_conf:.4f}\",\n","                ])\n","\n","                print(\n","                    f\"[IMAGE] {model_name}: \"\n","                    f\"avg latency = {avg_latency:.4f}s, FPS = {fps:.2f}, \"\n","                    f\"avg dets/img = {avg_dets:.2f}, avg conf = {avg_conf:.3f}\"\n","                )"],"metadata":{"id":"jk96ew25NrH_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================================\n","# 3) ACCURACY EVALUATION (.val) + PER-CLASS AP\n","# ============================================================\n","\n","def evaluate_accuracy(models: dict, data_yaml: str, split: str = \"val\"):\n","    if data_yaml is None or not os.path.isfile(data_yaml):\n","        print(\"[WARN] DATA_YAML not provided or file not found. Skipping accuracy evaluation.\")\n","        return\n","\n","    metrics_csv = os.path.join(REPORTS_DIR, \"accuracy_metrics.csv\")\n","    per_class_csv = os.path.join(REPORTS_DIR, \"per_class_ap.csv\")\n","\n","    with open(metrics_csv, \"w\", newline=\"\") as f_global, \\\n","         open(per_class_csv, \"w\", newline=\"\") as f_pc:\n","\n","        global_writer = csv.writer(f_global)\n","        pc_writer = csv.writer(f_pc)\n","\n","        global_writer.writerow([\n","            \"model\", \"dataset_split\",\n","            \"map_50_95\", \"map_50\",\n","            \"precision\", \"recall\",\n","            \"speed_preprocess_ms\", \"speed_inference_ms\", \"speed_postprocess_ms\"\n","        ])\n","\n","        pc_writer.writerow([\n","            \"model\", \"class_id\", \"class_name\",\n","            \"map_50_95\", \"map_50\"   # per-class mAP@0.5:0.95 and mAP@0.5\n","        ])\n","\n","        for model_name, model in models.items():\n","            print(f\"\\n[INFO] VAL evaluation for model: {model_name}\")\n","            metrics = model.val(\n","                data=data_yaml,\n","                split=split,\n","                imgsz=IMG_SIZE,\n","                device=DEVICE,\n","                conf=CONF_THRES,\n","                iou=IOU_THRES,\n","                verbose=False\n","            )\n","\n","            # ---- Global metrics ----\n","            try:\n","                map_50_95 = float(metrics.box.map)     # mAP@0.5:0.95\n","                map_50 = float(metrics.box.map50)      # mAP@0.5\n","                precision = float(metrics.box.mp)      # mean precision\n","                recall = float(metrics.box.mr)         # mean recall\n","\n","                sp = metrics.speed\n","                sp_p = float(sp.get(\"preprocess\", 0.0))\n","                sp_i = float(sp.get(\"inference\", 0.0))\n","                sp_o = float(sp.get(\"postprocess\", 0.0))\n","            except Exception as e:\n","                print(f\"[WARN] Could not parse global metrics for {model_name}: {e}\")\n","                map_50_95 = map_50 = precision = recall = 0.0\n","                sp_p = sp_i = sp_o = 0.0\n","\n","            global_writer.writerow([\n","                model_name, split,\n","                f\"{map_50_95:.4f}\",\n","                f\"{map_50:.4f}\",\n","                f\"{precision:.4f}\",\n","                f\"{recall:.4f}\",\n","                f\"{sp_p:.3f}\", f\"{sp_i:.3f}\", f\"{sp_o:.3f}\"\n","            ])\n","\n","            print(\n","                f\"[VAL] {model_name}: \"\n","                f\"mAP50-95={map_50_95:.4f}, mAP50={map_50:.4f}, \"\n","                f\"P={precision:.4f}, R={recall:.4f}\"\n","            )\n","\n","            # ---- Per-class AP ----\n","            try:\n","                # maps: array-like, mAP@0.5:0.95 for each class\n","                maps = metrics.box.maps  # shape [num_classes]\n","                # Some versions also expose map50s\n","                map50s = getattr(metrics.box, \"map50s\", None)\n","\n","                # Class names: try metrics.names, fallback to model.names\n","                if hasattr(metrics, \"names\") and metrics.names is not None:\n","                    names = metrics.names\n","                else:\n","                    names = model.names\n","\n","                # names may be dict or list\n","                if isinstance(names, dict):\n","                    id_to_name = names\n","                else:\n","                    id_to_name = {i: n for i, n in enumerate(names)}\n","\n","                num_classes = len(maps)\n","\n","                for cid in range(num_classes):\n","                    cls_name = id_to_name.get(cid, f\"class_{cid}\")\n","                    ap_50_95 = float(maps[cid])\n","                    if map50s is not None:\n","                        ap_50 = float(map50s[cid])\n","                    else:\n","                        # Fallback: use global map50 if per-class not available\n","                        ap_50 = map_50\n","\n","                    pc_writer.writerow([\n","                        model_name, cid, cls_name,\n","                        f\"{ap_50_95:.44f}\",\n","                        f\"{ap_50:.4f}\"\n","                    ])\n","\n","            except Exception as e:\n","                print(f\"[WARN] Could not parse per-class AP for {model_name}: {e}\")"],"metadata":{"id":"8e-PuzPoN1iY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================================\n","# 4) PLOTTING\n","# ============================================================\n","\n","def plot_fps_vs_map(\n","    accuracy_csv: str,\n","    video_summary_csv: str,\n","    out_path: str\n","):\n","    \"\"\"\n","    Scatter plot: FPS (x-axis) vs mAP50-95 (y-axis)\n","    One point per model.\n","    \"\"\"\n","    if not (os.path.isfile(accuracy_csv) and os.path.isfile(video_summary_csv)):\n","        print(\"[WARN] FPS vs mAP plot skipped (CSV missing).\")\n","        return\n","\n","    # Read mAP\n","    map_dict = {}  # model -> mAP50-95\n","    with open(accuracy_csv, \"r\") as f:\n","        reader = csv.DictReader(f)\n","        for row in reader:\n","            model = row[\"model\"]\n","            map_50_95 = float(row[\"map_50_95\"])\n","            map_dict[model] = map_50_95\n","\n","    # Read FPS (from video benchmark)\n","    fps_dict = {}  # model -> FPS\n","    with open(video_summary_csv, \"r\") as f:\n","        reader = csv.DictReader(f)\n","        for row in reader:\n","            model = row[\"model\"]\n","            fps = float(row[\"fps\"])\n","            fps_dict[model] = fps\n","\n","    models_common = sorted(set(map_dict.keys()) & set(fps_dict.keys()))\n","    if not models_common:\n","        print(\"[WARN] No overlapping models for FPS vs mAP plot.\")\n","        return\n","\n","    xs = [fps_dict[m] for m in models_common]\n","    ys = [map_dict[m] for m in models_common]\n","\n","    plt.figure()\n","    plt.scatter(xs, ys)\n","    for x, y, label in zip(xs, ys, models_common):\n","        plt.text(x, y, label, fontsize=9, ha=\"right\", va=\"bottom\")\n","\n","    plt.xlabel(\"Video FPS (higher is better)\")\n","    plt.ylabel(\"mAP@0.5:0.95 (higher is better)\")\n","    plt.title(\"Speed vs Accuracy: YOLO Models Comparison\")\n","    plt.grid(True)\n","    plt.tight_layout()\n","    plt.savefig(out_path, dpi=300)\n","    plt.close()\n","    print(f\"[PLOT] Saved FPS vs mAP plot to: {out_path}\")\n","\n","\n","def plot_per_class_ap(per_class_csv: str, out_dir: str):\n","    \"\"\"\n","    For each model, plot per-class mAP50-95 as a bar chart.\n","    \"\"\"\n","    if not os.path.isfile(per_class_csv):\n","        print(\"[WARN] per_class_ap.csv not found. Skipping per-class AP plots.\")\n","        return\n","\n","    # Load data by model\n","    model_to_records = {}  # model -> list of (class_name, map_50_95)\n","    with open(per_class_csv, \"r\") as f:\n","        reader = csv.DictReader(f)\n","        for row in reader:\n","            model = row[\"model\"]\n","            cls_name = row[\"class_name\"]\n","            ap_50_95 = float(row[\"map_50_95\"])\n","            model_to_records.setdefault(model, []).append((cls_name, ap_50_95))\n","\n","    for model, records in model_to_records.items():\n","        # Sort by AP descending for nicer plots\n","        records_sorted = sorted(records, key=lambda x: x[1], reverse=True)\n","        class_names = [r[0] for r in records_sorted]\n","        ap_values = [r[1] for r in records_sorted]\n","\n","        plt.figure(figsize=(max(6, 0.4 * len(class_names)), 4))\n","        x = range(len(class_names))\n","        plt.bar(x, ap_values)\n","        plt.xticks(x, class_names, rotation=45, ha=\"right\")\n","        plt.ylabel(\"mAP@0.5:0.95\")\n","        plt.ylim(0.0, 1.0)\n","        plt.title(f\"Per-class AP (mAP@0.5:0.95) - {model}\")\n","        plt.tight_layout()\n","\n","        out_path = os.path.join(out_dir, f\"per_class_ap_{model}.png\")\n","        plt.savefig(out_path, dpi=300)\n","        plt.close()\n","        print(f\"[PLOT] Saved per-class AP plot for {model} to: {out_path}\")\n"],"metadata":{"id":"1IfCO5axN4gD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================================\n","# MAIN\n","# ============================================================\n","\n","def main():\n","    print(\"[INFO] Starting YOLO model comparison...\")\n","\n","    models = load_models(MODEL_PATHS)\n","\n","    # 1) Images\n","    benchmark_on_images(models, IMAGES_DIR)\n","\n","    # 3) Accuracy (val/test)\n","    evaluate_accuracy(models, DATA_YAML, split=VAL_SPLIT)\n","\n","    # 4) Plots\n","    accuracy_csv = os.path.join(REPORTS_DIR, \"accuracy_metrics.csv\")\n","    video_csv = os.path.join(REPORTS_DIR, \"video_summary_stats.csv\")\n","    per_class_csv = os.path.join(REPORTS_DIR, \"per_class_ap.csv\")\n","\n","    # FPS vs mAP\n","    fps_map_plot_path = os.path.join(PLOTS_DIR, \"fps_vs_map50_95.png\")\n","    plot_fps_vs_map(accuracy_csv, video_csv, fps_map_plot_path)\n","\n","    # Per-class AP\n","    plot_per_class_ap(per_class_csv, PLOTS_DIR)\n","\n","    print(\"\\n[INFO] All benchmarks and plots finished.\")\n","    print(f\"[INFO] Check outputs under: {OUTPUT_ROOT}/\")\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PHCpCtAMN92l","executionInfo":{"status":"ok","timestamp":1765378419063,"user_tz":-330,"elapsed":12380,"user":{"displayName":"MATLAB PROJECT","userId":"00610724416781930528"}},"outputId":"47baafce-c40f-4b8b-ba71-69081ce1e73b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Starting YOLO model comparison...\n","[INFO] Loading model 'yolov8l_base' from models/yolov8l.pt ...\n","[INFO] Loading model 'yolo11l_base' from models/yolo11l.pt ...\n","[INFO] Loading model 'yolo11l_trained' from models/yolo11l_251019.pt ...\n","[INFO] Found 23 images in data/images\n","\n","[INFO] IMAGE benchmark for model: yolov8l_base\n","[IMAGE] yolov8l_base: avg latency = 0.1192s, FPS = 8.39, avg dets/img = 14.13, avg conf = 0.758\n","\n","[INFO] IMAGE benchmark for model: yolo11l_base\n","[IMAGE] yolo11l_base: avg latency = 0.0895s, FPS = 11.18, avg dets/img = 13.43, avg conf = 0.738\n","\n","[INFO] IMAGE benchmark for model: yolo11l_trained\n","[IMAGE] yolo11l_trained: avg latency = 0.0854s, FPS = 11.70, avg dets/img = 7.04, avg conf = 0.729\n","[WARN] DATA_YAML not provided or file not found. Skipping accuracy evaluation.\n","[WARN] FPS vs mAP plot skipped (CSV missing).\n","[WARN] per_class_ap.csv not found. Skipping per-class AP plots.\n","\n","[INFO] All benchmarks and plots finished.\n","[INFO] Check outputs under: outputs_compare/\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"13wjyXxSBXI41ImmKr9H5ZBxOXAvYjPJn","authorship_tag":"ABX9TyPzhzPXN7QdsVqdYJnp5vzz"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}