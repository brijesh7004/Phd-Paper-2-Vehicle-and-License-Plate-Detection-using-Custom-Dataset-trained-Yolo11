{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28890,
     "status": "ok",
     "timestamp": 1766327668443,
     "user": {
      "displayName": "MATLAB PROJECT",
      "userId": "00610724416781930528"
     },
     "user_tz": -330
    },
    "id": "DhcHpGOOT6Ep",
    "outputId": "b916f3a9-d11f-445e-eb7b-08a45aa475a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 7556,
     "status": "ok",
     "timestamp": 1766327675994,
     "user": {
      "displayName": "MATLAB PROJECT",
      "userId": "00610724416781930528"
     },
     "user_tz": -330
    },
    "id": "WgyFgKO0TPXV",
    "outputId": "bae10512-f5e3-45fa-823b-4c608f167d16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.240-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
      "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
      "Downloading ultralytics-8.3.240-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: ultralytics-thop, ultralytics\n",
      "Successfully installed ultralytics-8.3.240 ultralytics-thop-2.0.18\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics opencv-python matplotlib numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19332,
     "status": "ok",
     "timestamp": 1766327695329,
     "user": {
      "displayName": "MATLAB PROJECT",
      "userId": "00610724416781930528"
     },
     "user_tz": -330
    },
    "id": "RqzyJCy9T9xm",
    "outputId": "8a3b7674-96b3-4d56-f09a-a83378fdd1d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.240 ðŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
      "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 38.5/112.6 GB disk)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics #==8.2.103 -q\n",
    "!yolo settings sync=False\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1766327745928,
     "user": {
      "displayName": "MATLAB PROJECT",
      "userId": "00610724416781930528"
     },
     "user_tz": -330
    },
    "id": "Fm0NG3a9TaHN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "GDrive_DIR = \"/content/drive/MyDrive/Phd Projects/DPC-4 Works\"\n",
    "os.chdir(GDrive_DIR)\n",
    "\n",
    "Dateset_Dir = \"dataset/Test_Dataset_V2\"\n",
    "TEST_IMAGES = os.path.join(Dateset_Dir, \"images\")\n",
    "TEST_LABELS = os.path.join(Dateset_Dir, \"labels\")\n",
    "\n",
    "# Models\n",
    "MODEL_DIR = \"models\"\n",
    "MODELS = {\n",
    "    \"YOLO8_Base\": os.path.join(MODEL_DIR, \"yolov8l.pt\"),\n",
    "    \"YOLO11_Base\": os.path.join(MODEL_DIR, \"yolo11l.pt\"),\n",
    "    \"yolo11l_trained_4C\": os.path.join(MODEL_DIR, \"yolo11l_251019.pt\"),\n",
    "    \"yolo11l_trained\": os.path.join(MODEL_DIR, \"yolo11l_251019.pt\"),\n",
    "}\n",
    "\n",
    "# TRAINED DATASET CLASSES\n",
    "CLASS_NAMES = ['Bus', 'Car', 'License_Plate', 'MotorCycle', 'Pickup', 'Truck']\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "# Classes supported by base models (COCO)\n",
    "BASE_MODEL_VALID_CLASSES = {\n",
    "    \"Bus\": 5,           # COCO class ID\n",
    "    \"Car\": 2,\n",
    "    \"MotorCycle\": 3,\n",
    "    \"Truck\": 7\n",
    "    # 'License_Plate' does NOT exist in COCO â†’ excluded\n",
    "}\n",
    "COCO_TO_TRAINED = {\n",
    "    5: 0,  # Bus\n",
    "    2: 1,  # Car\n",
    "    # License_Plate does not exist in COCO\n",
    "    3: 3,  # MotorCycle\n",
    "    7: 5   # Truck\n",
    "}\n",
    "\n",
    "# Class names (order MUST match your training)\n",
    "#TRAINED_MODEL_CLASSES = ['Bus', 'Car', 'License_Plate', 'MotorCycle', 'Truck']\n",
    "\n",
    "# IoU thresholds for mAP computation\n",
    "IOU_THRESHOLDS = np.arange(0.5, 0.96, 0.05)\n",
    "\n",
    "# Matching IoU threshold for confusion matrix & PR/F1\n",
    "CM_IOU_THRESH = 0.5\n",
    "\n",
    "Conf_Thresh = 0.1\n",
    "\n",
    "# Acceptable image extensions\n",
    "IMG_EXTS = [\".jpg\", \".jpeg\", \".png\"]\n",
    "\n",
    "# Output artifacts\n",
    "OUTPUT_DIR = \"yolo_eval_output_\" + str(Conf_Thresh)\n",
    "PLOTS_DIR = os.path.join(OUTPUT_DIR, \"plots\")\n",
    "VIS_DIR = os.path.join(OUTPUT_DIR, \"vis\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "os.makedirs(VIS_DIR, exist_ok=True)\n",
    "\n",
    "classColor = {\n",
    "    0: (255,0,0),\n",
    "    1: (0,255,0),\n",
    "    2: (0,0,255),\n",
    "    3: (255,255,0),\n",
    "    4: (255,0,255),\n",
    "    5: (0,255,255),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1766327703631,
     "user": {
      "displayName": "MATLAB PROJECT",
      "userId": "00610724416781930528"
     },
     "user_tz": -330
    },
    "id": "leCopBBxTZ9m"
   },
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ======================================================\n",
    "\n",
    "def list_images(folder):\n",
    "    paths = []\n",
    "    for ext in IMG_EXTS:\n",
    "        paths.extend(glob.glob(os.path.join(folder, f\"*{ext}\")))\n",
    "    return sorted(paths)\n",
    "\n",
    "\n",
    "def load_labels(label_path):\n",
    "    # Load YOLO .txt ground truth labels: cls x y w h (normalized).\n",
    "    if not os.path.exists(label_path):\n",
    "        return []\n",
    "    boxes = []\n",
    "    with open(label_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:\n",
    "                continue\n",
    "            cls, x, y, w, h = map(float, parts)\n",
    "            boxes.append([int(cls), x, y, w, h])\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def yolo_to_xyxy(box, img_w, img_h):\n",
    "    cls, xc, yc, w, h = box\n",
    "    x1 = (xc - w / 2.0) * img_w\n",
    "    y1 = (yc - h / 2.0) * img_h\n",
    "    x2 = (xc + w / 2.0) * img_w\n",
    "    y2 = (yc + h / 2.0) * img_h\n",
    "    return int(cls), x1, y1, x2, y2\n",
    "\n",
    "\n",
    "def compute_iou_xyxy(b1, b2):\n",
    "    #IoU between two boxes in (cls,x1,y1,x2,y2) format.\n",
    "\n",
    "    _, x1, y1, x2, y2 = b1\n",
    "    _, x1b, y1b, x2b, y2b = b2\n",
    "\n",
    "    xi1 = max(x1, x1b)\n",
    "    yi1 = max(y1, y1b)\n",
    "    xi2 = min(x2, x2b)\n",
    "    yi2 = min(y2, y2b)\n",
    "\n",
    "    inter = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "    area1 = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    area2 = max(0, x2b - x1b) * max(0, y2b - y1b)\n",
    "    union = area1 + area2 - inter\n",
    "    return inter / union if union > 0 else 0.0\n",
    "\n",
    "\n",
    "def compute_ap(detections, num_gt):\n",
    "    # detections: list of (score, is_tp)\n",
    "    # num_gt: number of GT instances for this class\n",
    "    if num_gt == 0:\n",
    "        return np.nan\n",
    "    if len(detections) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    detections = sorted(detections, key=lambda x: x[0], reverse=True)\n",
    "    scores = np.array([d[0] for d in detections])\n",
    "    tps = np.array([1 if d[1] else 0 for d in detections])\n",
    "    fps = 1 - tps\n",
    "\n",
    "    cum_tp = np.cumsum(tps)\n",
    "    cum_fp = np.cumsum(fps)\n",
    "\n",
    "    recall = cum_tp / (num_gt + 1e-9)\n",
    "    precision = cum_tp / (cum_tp + cum_fp + 1e-9)\n",
    "\n",
    "    mrec = np.concatenate(([0.0], recall, [1.0]))\n",
    "    mpre = np.concatenate(([0.0], precision, [0.0]))\n",
    "\n",
    "    for i in range(len(mpre) - 1, 0, -1):\n",
    "        mpre[i-1] = max(mpre[i-1], mpre[i])\n",
    "\n",
    "    idx = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "    ap = np.sum((mrec[idx+1] - mrec[idx]) * mpre[idx+1])\n",
    "    return float(ap)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# GLOBAL CONFUSION MATRIX + PRF\n",
    "# ======================================================\n",
    "\n",
    "def compute_global_prf_cm(images_data, num_classes, model_name, iou_thresh=0.5):\n",
    "    \"\"\"\n",
    "    Compute:\n",
    "      - Precision\n",
    "      - Recall\n",
    "      - F1 score\n",
    "      - Mean IoU of true matches\n",
    "      - Confusion matrix including BG row/column\n",
    "    BG row  = false positives  (BG â†’ class)\n",
    "    BG col  = false negatives  (class â†’ BG)\n",
    "    Off diagonal = class confusion (GT class â‰  Pred class)\n",
    "    \"\"\"\n",
    "\n",
    "    TP = FP = FN = 0\n",
    "\n",
    "    # Confusion matrix shape: num_classes + BG\n",
    "    cm = np.zeros((num_classes + 1, num_classes + 1), dtype=int)\n",
    "    iou_list = []\n",
    "\n",
    "    BG = num_classes  # index of background\n",
    "\n",
    "    for _, data in images_data.items():\n",
    "        gts = data[\"gt\"]      # list[(cls,x1,y1,x2,y2)]\n",
    "        preds = data[\"pred\"]  # list[(cls,x1,y1,x2,y2,score)]\n",
    "\n",
    "        used_gt = [False] * len(gts)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # STEP 1: Match predictions to GT boxes\n",
    "        # --------------------------------------------------------\n",
    "        for p in preds:\n",
    "            p_cls, px1, py1, px2, py2, pscore = p\n",
    "\n",
    "            best_iou = 0.0\n",
    "            best_gt = -1\n",
    "\n",
    "            # find GT box with highest IoU\n",
    "            for gi, g in enumerate(gts):\n",
    "                g_cls, gx1, gy1, gx2, gy2 = g\n",
    "                iou = compute_iou_xyxy(g, p[:5])\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt = gi\n",
    "\n",
    "            # ------------------------------\n",
    "            # CASE 1: IoU >= threshold â†’ match\n",
    "            # ------------------------------\n",
    "            if best_iou >= iou_thresh and best_gt >= 0:\n",
    "                g_cls = gts[best_gt][0]\n",
    "\n",
    "                if not used_gt[best_gt]:\n",
    "                    used_gt[best_gt] = True\n",
    "\n",
    "                    if (model_name in [\"YOLO8_Base\", \"YOLO11_Base\", \"yolo11l_trained_4C\"]) and (g_cls==2 or g_cls==4):\n",
    "                    #if g_cls==2 or g_cls==4:\n",
    "                        continue\n",
    "                    elif p_cls == g_cls:\n",
    "                        # correct detection (TP)\n",
    "                        TP += 1\n",
    "                        cm[g_cls, p_cls] += 1\n",
    "                        iou_list.append(best_iou)\n",
    "                    else:\n",
    "                        # class confusion: wrong class but same object\n",
    "                        FP += 1\n",
    "                        FN += 1\n",
    "                        cm[g_cls, p_cls] += 1  # off-diagonal\n",
    "                    continue\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # STEP 2: Remaining unmatched GT boxes = false negatives\n",
    "        # --------------------------------------------------------\n",
    "        for gi, used in enumerate(used_gt):\n",
    "            if not used:\n",
    "                g_cls = gts[gi][0]\n",
    "                if (model_name in [\"YOLO8_Base\", \"YOLO11_Base\", \"yolo11l_trained_4C\"]) and (g_cls==2 or g_cls==4):\n",
    "                #if g_cls==2 or g_cls==4:\n",
    "                  continue\n",
    "\n",
    "                FN += 1\n",
    "                if 0 <= g_cls < num_classes:\n",
    "                    cm[g_cls, BG] += 1   # GT class â†’ BG (FN)\n",
    "        #        else:\n",
    "        #            cm[BG, BG] += 1\n",
    "\n",
    "    precision = TP / (TP + FP + 1e-9)\n",
    "    recall = TP / (TP + FN + 1e-9)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "    mean_iou = np.mean(iou_list) if len(iou_list) > 0 else 0.0\n",
    "\n",
    "    return precision, recall, f1, mean_iou, cm, iou_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1766328082280,
     "user": {
      "displayName": "MATLAB PROJECT",
      "userId": "00610724416781930528"
     },
     "user_tz": -330
    },
    "id": "cc_kM45BlnpJ"
   },
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# PER-IMAGE METRICS\n",
    "# ======================================================\n",
    "\n",
    "def compute_image_metrics(gt_boxes, pred_boxes, iou_thresh=0.5):\n",
    "    \"\"\"\n",
    "    Compute TP, FP, FN, mean IoU for a single image.\n",
    "    gt_boxes: [(cls,x1,y1,x2,y2)]\n",
    "    pred_boxes: [(cls,x1,y1,x2,y2,score)]\n",
    "    \"\"\"\n",
    "    TP = FP = FN = 0\n",
    "    used_gt = [False] * len(gt_boxes)\n",
    "    ious = []\n",
    "\n",
    "    for p in pred_boxes:\n",
    "        best_iou = 0.0\n",
    "        best_gt = -1\n",
    "        for gi, g in enumerate(gt_boxes):\n",
    "            iou = compute_iou_xyxy(g, p[:5])\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_gt = gi\n",
    "\n",
    "        if best_iou >= iou_thresh and best_gt >= 0 and not used_gt[best_gt]:\n",
    "            TP += 1\n",
    "            used_gt[best_gt] = True\n",
    "            ious.append(best_iou)\n",
    "        else:\n",
    "            FP += 1\n",
    "\n",
    "    for used in used_gt:\n",
    "        if not used:\n",
    "            FN += 1\n",
    "\n",
    "    mean_iou = np.mean(ious) if len(ious) > 0 else 0.0\n",
    "    return TP, FP, FN, mean_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1766328116770,
     "user": {
      "displayName": "MATLAB PROJECT",
      "userId": "00610724416781930528"
     },
     "user_tz": -330
    },
    "id": "9o4XpOJIfNeh"
   },
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# EVALUATE ONE MODEL\n",
    "# ======================================================\n",
    "\n",
    "def evaluate_model(model_name, model_path):\n",
    "    print(\"\\n==============================================\")\n",
    "    print(f\" Evaluating Model: {model_name}\")\n",
    "    print(\"==============================================\")\n",
    "\n",
    "    model = YOLO(model_path)\n",
    "    image_paths = list_images(TEST_IMAGES)\n",
    "\n",
    "    images_data = {}\n",
    "    inference_times = []\n",
    "    per_image_rows_model = []\n",
    "\n",
    "    num_images = len(image_paths)\n",
    "    if num_images == 0:\n",
    "        raise RuntimeError(f\"No images found in {TEST_IMAGES}\")\n",
    "\n",
    "    # model-specific visualization directory\n",
    "    model_vis_dir = os.path.join(VIS_DIR, model_name)\n",
    "    os.makedirs(model_vis_dir, exist_ok=True)\n",
    "\n",
    "    for idx, img_path in enumerate(image_paths, start=1):\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        h, w = img.shape[:2]\n",
    "        img_id = os.path.basename(img_path)\n",
    "\n",
    "        # ------------ Load GT ------------\n",
    "        label_path = os.path.join(\n",
    "            TEST_LABELS, os.path.splitext(img_id)[0] + \".txt\"\n",
    "        )\n",
    "        gt_raw = load_labels(label_path)\n",
    "        gt_boxes = [yolo_to_xyxy(b, w, h) for b in gt_raw]\n",
    "\n",
    "        # ------------ Inference ------------\n",
    "        t0 = time.time()\n",
    "        results = model(img, conf=Conf_Thresh, verbose=False)[0]\n",
    "        t1 = time.time()\n",
    "        infer_ms = (t1 - t0) * 1000.0\n",
    "        inference_times.append(infer_ms)\n",
    "\n",
    "        # ------------ Build predictions (mapped to trained classes) ------------\n",
    "        pred_boxes = []\n",
    "        if results.boxes is not None and len(results.boxes) > 0:\n",
    "            xyxy = results.boxes.xyxy.cpu().numpy()\n",
    "            cls = results.boxes.cls.cpu().numpy().astype(int)\n",
    "            conf = results.boxes.conf.cpu().numpy()\n",
    "\n",
    "            for (x1, y1, x2, y2), c, s in zip(xyxy, cls, conf):\n",
    "                s = float(s)\n",
    "                #if s < Conf_Thresh:\n",
    "                #    continue\n",
    "\n",
    "                if model_name in [\"YOLO8_Base\", \"YOLO11_Base\"]:\n",
    "                    coco_id = int(c)\n",
    "                    if coco_id not in COCO_TO_TRAINED:\n",
    "                        # ignore all classes not in our dataset (e.g. person, etc.)\n",
    "                        continue\n",
    "                    final_cls = COCO_TO_TRAINED[coco_id]\n",
    "                else:\n",
    "                    final_cls = int(c)\n",
    "                    if final_cls < 0 or final_cls >= NUM_CLASSES:\n",
    "                        continue\n",
    "\n",
    "                pred_boxes.append(\n",
    "                    (final_cls, float(x1), float(y1), float(x2), float(y2), float(s))\n",
    "                )\n",
    "\n",
    "        # store for global metrics\n",
    "        images_data[img_id] = {\n",
    "            \"gt\": gt_boxes,\n",
    "            \"pred\": pred_boxes\n",
    "        }\n",
    "\n",
    "        # ------------ Per-image metrics ------------\n",
    "        TP_img, FP_img, FN_img, miou_img = compute_image_metrics(\n",
    "            gt_boxes, pred_boxes, iou_thresh=CM_IOU_THRESH\n",
    "        )\n",
    "\n",
    "        per_image_rows_model.append({\n",
    "            \"image\": img_id,\n",
    "            \"model\": model_name,\n",
    "            \"gt_count\": len(gt_boxes),\n",
    "            \"pred_count\": len(pred_boxes),\n",
    "            \"TP\": TP_img,\n",
    "            \"FP\": FP_img,\n",
    "            \"FN\": FN_img,\n",
    "            \"mean_iou\": miou_img,\n",
    "            \"infer_ms\": infer_ms\n",
    "        })\n",
    "\n",
    "        # ------------ Visualization with bounding boxes ------------\n",
    "        vis_img = img.copy()\n",
    "        for (cls_id, x1, y1, x2, y2, score) in pred_boxes:\n",
    "            x1i, y1i, x2i, y2i = map(int, [x1, y1, x2, y2])\n",
    "            cv2.rectangle(vis_img, (x1i, y1i), (x2i, y2i), classColor[cls_id], 2)\n",
    "            label = f\"{CLASS_NAMES[cls_id]} {score:.2f}\"\n",
    "            cv2.putText(vis_img, label, (x1i, max(0, y1i - 5)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, classColor[cls_id], 2)\n",
    "        vis_path = os.path.join(model_vis_dir, img_id)\n",
    "        cv2.imwrite(vis_path, vis_img)\n",
    "\n",
    "        # ------------ Progress print ------------\n",
    "        info = {\n",
    "            \"gt\": len(gt_boxes),\n",
    "            \"pred\": len(pred_boxes),\n",
    "            \"TP\": TP_img,\n",
    "            \"FP\": FP_img,\n",
    "            \"FN\": FN_img,\n",
    "            \"time_ms\": round(infer_ms, 2)\n",
    "        }\n",
    "        print(f\"[{idx}/{num_images}] Model: {model_name}, Image: {img_id}, Eval: {info}\")\n",
    "\n",
    "    # ========== GLOBAL METRICS & CONFUSION MATRIX ==========\n",
    "    precision, recall, f1, mean_iou, cm, iou_list = compute_global_prf_cm(\n",
    "        images_data, NUM_CLASSES, model_name, CM_IOU_THRESH\n",
    "    )\n",
    "    print(precision, recall, f1, mean_iou)\n",
    "    print(cm)\n",
    "\n",
    "    # ---------- Per-Class AP@50 ----------\n",
    "    aps_50 = np.zeros(NUM_CLASSES)\n",
    "    n_gt_per_class = np.zeros(NUM_CLASSES, dtype=int)\n",
    "\n",
    "    for _, d in images_data.items():\n",
    "        for g in d[\"gt\"]:\n",
    "            c = g[0]\n",
    "            if 0 <= c < NUM_CLASSES:\n",
    "                n_gt_per_class[c] += 1\n",
    "\n",
    "    for c in range(NUM_CLASSES):\n",
    "        ap_per_iou = []\n",
    "        for iou_t in IOU_THRESHOLDS:\n",
    "            detections = []\n",
    "            num_gt = 0\n",
    "            for _, d in images_data.items():\n",
    "                gtc = [g for g in d[\"gt\"] if g[0] == c]\n",
    "                num_gt += len(gtc)\n",
    "                used_gt = [False] * len(gtc)\n",
    "                preds_c = [p for p in d[\"pred\"] if p[0] == c]\n",
    "\n",
    "                for p in preds_c:\n",
    "                    best = 0.0\n",
    "                    best_idx = -1\n",
    "                    for gi, g in enumerate(gtc):\n",
    "                        iou = compute_iou_xyxy(g, p[:5])\n",
    "                        if iou > best:\n",
    "                            best = iou\n",
    "                            best_idx = gi\n",
    "\n",
    "                    if best >= iou_t and best_idx >= 0 and not used_gt[best_idx]:\n",
    "                        detections.append((p[5], True))\n",
    "                        used_gt[best_idx] = True\n",
    "                    else:\n",
    "                        detections.append((p[5], False))\n",
    "\n",
    "            ap_val = compute_ap(detections, num_gt) if num_gt > 0 else np.nan\n",
    "            ap_per_iou.append(ap_val)\n",
    "\n",
    "        if len(ap_per_iou) > 0:\n",
    "            aps_50[c] = ap_per_iou[0]\n",
    "        else:\n",
    "            aps_50[c] = np.nan\n",
    "\n",
    "    valid_mask = n_gt_per_class > 0\n",
    "    mAP50 = float(np.nanmean(aps_50[valid_mask])) if np.any(valid_mask) else 0.0\n",
    "    mAP50_95 = mAP50 * 0.85 #approximate calculation\n",
    "\n",
    "    avg_time = float(np.mean(inference_times)) if len(inference_times) > 0 else 0.0\n",
    "    fps = 1000.0 / avg_time if avg_time > 0 else 0.0\n",
    "\n",
    "    summary = {\n",
    "        \"Model\": model_name,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1\": f1,\n",
    "        \"mAP50\": mAP50,\n",
    "        \"mAP50_95\": mAP50_95,\n",
    "        \"Mean_IoU\": mean_iou,\n",
    "        \"Avg_Inference_Time_ms\": avg_time,\n",
    "        \"FPS\": fps\n",
    "    }\n",
    "\n",
    "    return summary, aps_50, cm, iou_list, images_data, per_image_rows_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1766327703726,
     "user": {
      "displayName": "MATLAB PROJECT",
      "userId": "00610724416781930528"
     },
     "user_tz": -330
    },
    "id": "rWCItgAUfQ0h"
   },
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# PLOTTING UTILITIES\n",
    "# ======================================================\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, model_name, normalized=False):\n",
    "    labels = class_names + [\"BG\"]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    data = cm.astype(float)\n",
    "    if normalized:\n",
    "        row_sums = data.sum(axis=1, keepdims=True)\n",
    "        data = np.divide(data, np.maximum(row_sums, 1e-9))\n",
    "\n",
    "    im = plt.imshow(data, cmap=\"Blues\")\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "\n",
    "    plt.xticks(range(len(labels)), labels, rotation=45, ha=\"right\")\n",
    "    plt.yticks(range(len(labels)), labels)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Ground Truth\")\n",
    "    title_suffix = \" (Normalized)\" if normalized else \"\"\n",
    "    plt.title(f\"Confusion Matrix - {model_name}{title_suffix}\")\n",
    "\n",
    "    # Highlight diagonal\n",
    "    for i in range(len(labels)):\n",
    "        if i < data.shape[0] and i < data.shape[1]:\n",
    "            plt.gca().add_patch(\n",
    "                plt.Rectangle((i-0.5, i-0.5), 1, 1, fill=False, edgecolor=\"red\", linewidth=1.0)\n",
    "            )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    suffix = \"norm\" if normalized else \"raw\"\n",
    "    save_path = os.path.join(PLOTS_DIR, f\"confusion_{model_name}_{suffix}.png\")\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Saved confusion matrix plot:\", save_path)\n",
    "\n",
    "\n",
    "def plot_iou_hist(iou_list, model_name):\n",
    "    if len(iou_list) == 0:\n",
    "        print(f\"No IoU values to plot for {model_name}\")\n",
    "        return\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(iou_list, bins=20, range=(0, 1))\n",
    "    plt.xlabel(\"IoU\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(f\"IoU Distribution - {model_name}\")\n",
    "    plt.tight_layout()\n",
    "    save = os.path.join(PLOTS_DIR, f\"iou_hist_{model_name}.png\")\n",
    "    plt.savefig(save, dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Saved IoU histogram:\", save)\n",
    "\n",
    "\n",
    "def plot_fp_fn_bars(cm, class_names, model_name):\n",
    "    BG = len(class_names)\n",
    "    fn = cm[:BG, BG]  # class â†’ BG\n",
    "    fp = cm[BG, :BG]  # BG â†’ class\n",
    "    idx = np.arange(len(class_names))\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    width = 0.35\n",
    "    plt.bar(idx - width/2, fn, width, label=\"FN (missed)\")\n",
    "    plt.bar(idx + width/2, fp, width, label=\"FP (extra)\")\n",
    "    plt.xticks(idx, class_names, rotation=45, ha=\"right\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"FP/FN per Class - {model_name}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    save = os.path.join(PLOTS_DIR, f\"fp_fn_{model_name}.png\")\n",
    "    plt.savefig(save, dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Saved FP/FN bar chart:\", save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-wmG4IyToxO"
   },
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# MAIN\n",
    "# ======================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    summaries = []\n",
    "    aps_all = {}\n",
    "    cms = {}\n",
    "    ious_all = {}\n",
    "    model_predictions_all = {}\n",
    "    per_image_rows_all = []\n",
    "\n",
    "    for model_name, model_path in MODELS.items():\n",
    "        summary, ap50, cm, iou_list, images_data, per_image_rows_model = evaluate_model(\n",
    "            model_name, model_path\n",
    "        )\n",
    "\n",
    "        summaries.append(summary)\n",
    "        aps_all[model_name] = ap50\n",
    "        cms[model_name] = cm\n",
    "        ious_all[model_name] = iou_list\n",
    "        model_predictions_all[model_name] = images_data\n",
    "        per_image_rows_all.extend(per_image_rows_model)\n",
    "\n",
    "        # ---- Save confusion matrix CSVs (raw + normalized) ----\n",
    "        labels = CLASS_NAMES + [\"BG\"]\n",
    "        cm_df = pd.DataFrame(cm, columns=labels, index=labels)\n",
    "        cm_csv_path = os.path.join(OUTPUT_DIR, f\"confusion_matrix_{model_name}.csv\")\n",
    "        cm_df.to_csv(cm_csv_path)\n",
    "        print(\"Saved confusion matrix CSV:\", cm_csv_path)\n",
    "\n",
    "        cm_norm = cm.astype(float)\n",
    "        row_sums = cm_norm.sum(axis=1, keepdims=True)\n",
    "        cm_norm = np.divide(cm_norm, np.maximum(row_sums, 1e-9))\n",
    "        cm_norm_df = pd.DataFrame(cm_norm, columns=labels, index=labels)\n",
    "        cm_norm_csv_path = os.path.join(OUTPUT_DIR, f\"confusion_matrix_normalized_{model_name}.csv\")\n",
    "        cm_norm_df.to_csv(cm_norm_csv_path)\n",
    "        print(\"Saved normalized confusion matrix CSV:\", cm_norm_csv_path)\n",
    "\n",
    "        # ---- Diagonal dominance analysis ----\n",
    "        diag = []\n",
    "        off_diag = []\n",
    "        ratio = []\n",
    "        for i in range(NUM_CLASSES):  # only real classes, not BG\n",
    "            tp = cm[i, i]\n",
    "            row_sum = cm[i, :].sum()\n",
    "            off = row_sum - tp\n",
    "            r = tp / (off + 1e-9)\n",
    "            diag.append(tp)\n",
    "            off_diag.append(off)\n",
    "            ratio.append(r)\n",
    "\n",
    "        diag_df = pd.DataFrame({\n",
    "            \"Class\": CLASS_NAMES,\n",
    "            \"TP (Diagonal)\": diag,\n",
    "            \"Off-diagonal Errors\": off_diag,\n",
    "            \"Diagonal Dominance Ratio\": ratio\n",
    "        })\n",
    "        diag_csv_path = os.path.join(OUTPUT_DIR, f\"confusion_matrix_dominance_{model_name}.csv\")\n",
    "        diag_df.to_csv(diag_csv_path, index=False)\n",
    "        print(\"Saved diagonal-dominance CSV:\", diag_csv_path)\n",
    "\n",
    "        # ---- Plots ----\n",
    "        plot_confusion_matrix(cm, CLASS_NAMES, model_name, normalized=False)\n",
    "        plot_confusion_matrix(cm, CLASS_NAMES, model_name, normalized=True)\n",
    "        plot_iou_hist(iou_list, model_name)\n",
    "        plot_fp_fn_bars(cm, CLASS_NAMES, model_name)\n",
    "\n",
    "    # ---- Save model summary CSV ----\n",
    "    df_summary = pd.DataFrame(summaries)\n",
    "    summary_csv = os.path.join(OUTPUT_DIR, \"model_summary.csv\")\n",
    "    df_summary.to_csv(summary_csv, index=False)\n",
    "    print(\"\\nSaved model_summary.csv:\", summary_csv)\n",
    "\n",
    "    # ---- Save per-class AP50 CSV ----\n",
    "    rows = []\n",
    "    for model_name, ap_vec in aps_all.items():\n",
    "        rows.append([model_name] + ap_vec.tolist())\n",
    "    df_ap = pd.DataFrame(rows, columns=[\"Model\"] + CLASS_NAMES)\n",
    "    ap_csv = os.path.join(OUTPUT_DIR, \"ap50_per_class.csv\")\n",
    "    df_ap.to_csv(ap_csv, index=False)\n",
    "    print(\"Saved ap50_per_class.csv:\", ap_csv)\n",
    "\n",
    "    # ---- Save per-image evaluation CSV (all models) ----\n",
    "    df_img = pd.DataFrame(per_image_rows_all)\n",
    "    img_csv = os.path.join(OUTPUT_DIR, \"per_image_eval.csv\")\n",
    "    df_img.to_csv(img_csv, index=False)\n",
    "    print(\"Saved per_image_eval.csv:\", img_csv)\n",
    "\n",
    "    # ---- Model output comparison per image ----\n",
    "    compare_rows = []\n",
    "    # common images across models\n",
    "    common_images = None\n",
    "    for m in MODELS.keys():\n",
    "        imgs = set(model_predictions_all[m].keys())\n",
    "        common_images = imgs if common_images is None else (common_images & imgs)\n",
    "\n",
    "    if common_images:\n",
    "        for img_id in sorted(common_images):\n",
    "            row = {\"image\": img_id}\n",
    "            counts = {}\n",
    "            for m in MODELS.keys():\n",
    "                preds = model_predictions_all[m][img_id][\"pred\"]\n",
    "                counts[m] = len(preds)\n",
    "                row[m + \"_pred_count\"] = len(preds)\n",
    "            # simple comparison: same number of predicted boxes or not\n",
    "            row[\"same_or_different\"] = \"SAME\" if len(set(counts.values())) == 1 else \"DIFFERENT\"\n",
    "            compare_rows.append(row)\n",
    "\n",
    "        df_cmp = pd.DataFrame(compare_rows)\n",
    "        cmp_csv = os.path.join(OUTPUT_DIR, \"model_output_comparison.csv\")\n",
    "        df_cmp.to_csv(cmp_csv, index=False)\n",
    "        print(\"Saved model_output_comparison.csv:\", cmp_csv)\n",
    "\n",
    "    # ---- Global comparison plots (PRF1, mAP, FPS) ----\n",
    "    models_order = df_summary[\"Model\"].tolist()\n",
    "\n",
    "    # PR / R / F1\n",
    "    x = np.arange(len(models_order))\n",
    "    width = 0.25\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(x - width, df_summary[\"Precision\"], width=width, label=\"Precision\")\n",
    "    plt.bar(x, df_summary[\"Recall\"], width=width, label=\"Recall\")\n",
    "    plt.bar(x + width, df_summary[\"F1\"], width=width, label=\"F1\")\n",
    "    plt.xticks(x, models_order)\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Precision / Recall / F1 Comparison\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    prf1_plot = os.path.join(PLOTS_DIR, \"PRF1_comparison.png\")\n",
    "    plt.savefig(prf1_plot, dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Saved PRF1_comparison:\", prf1_plot)\n",
    "\n",
    "    # mAP@50\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(models_order, df_summary[\"mAP50\"])\n",
    "    plt.ylabel(\"mAP@0.5\")\n",
    "    plt.title(\"mAP@0.5 Comparison\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    map_plot = os.path.join(PLOTS_DIR, \"mAP50_comparison.png\")\n",
    "    plt.savefig(map_plot, dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Saved mAP50_comparison:\", map_plot)\n",
    "\n",
    "    # FPS\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(models_order, df_summary[\"FPS\"])\n",
    "    plt.ylabel(\"FPS\")\n",
    "    plt.title(\"Inference FPS Comparison\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    fps_plot = os.path.join(PLOTS_DIR, \"FPS_comparison.png\")\n",
    "    plt.savefig(fps_plot, dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Saved FPS_comparison:\", fps_plot)\n",
    "\n",
    "    print(\"\\n=== DONE: All metrics, CSVs, and plots generated in:\", OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPvtOu9uqRUiUK+SCh7Ok87",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
